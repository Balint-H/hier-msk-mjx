import cv2
import numpy as np
import os
import h5py

import pickle

def images_to_video(image_array, output_filename="output.mp4", fps=30):
    """ This function was generated by ChatGPT.
    Convert an array of images (NumPy arrays) into an MP4 video and open it."""
    
    if len(image_array) == 0:
        print("No images to process.")
        return
    
    # Get dimensions from the first image
    height, width, layers = image_array[0].shape

    # Define the codec and create VideoWriter object
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4
    video_writer = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))

    for img in image_array:
        video_writer.write(img)

    video_writer.release()

    print(f"Video saved as {output_filename}")

    # Automatically open the video (cross-platform)
    if os.name == "nt":  # Windows
        os.startfile(output_filename)
    elif os.name == "posix":  # macOS/Linux
        os.system(f"open {output_filename}" if "darwin" in os.sys.platform else f"xdg-open {output_filename}")


if __name__ == "__main__":

    import mujoco
    from mujoco import mjx
    from mujoco_playground import registry, State
    from playground_elbow import PlaygroundElbow, default_config
    import h5py


    registry.locomotion.register_environment("MyoElbow", PlaygroundElbow, default_config)
    registry.locomotion.ALL.append("MyoElbow")

    scene_option = mujoco.MjvOption()
    scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False
    scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = False
    scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = False

    eval_env = registry.load("MyoElbow", default_config())
    with open(r'\\wsl.localhost\Ubuntu\home\simstation\emg_sim\myosuite\myosuite\envs\myo\mjx\traj.pickle', 'rb') as handle:
        traj = pickle.load(handle)

    def data_with_qpos(q):
        data = mujoco.MjData(eval_env.mj_model)
        data.qpos = q
        return data

    with h5py.File(r'traj.h5', 'r') as h5f:
        qpos = h5f['qpos']
        traj_h5 = [State(data_with_qpos(q), [0], 0, 0, {}, {}) for q in qpos]

    frames = eval_env.render(
        traj, height=480, width=640, scene_option=scene_option
    )

    frames_h5 = eval_env.render(
        traj_h5, height=480, width=640, scene_option=scene_option
    )
    render_every = 2
    fps = 1.0 / eval_env.dt / render_every
    images_to_video(frames, "rollout.mp4")
    images_to_video(frames_h5, "rollout_h5.mp4")
    print("Rollout video saved as 'rollout.mp4'.")